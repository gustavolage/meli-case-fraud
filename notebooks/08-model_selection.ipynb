{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71218024-7b0a-4436-9260-a685185ef8f1",
   "metadata": {},
   "source": [
    "---\n",
    "# Notebook para selecionarmos o melhor modelo, para que no próximo passo façamos o tunning do melhor modelo.\n",
    "\n",
    "Vamos testar 3 abordagens de modelos:\n",
    "\n",
    "- __Logistic Regression__\n",
    "\n",
    "- __Random Forest__\n",
    "\n",
    "- __Boosting__\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def62c9a-728e-468b-bd86-3e912b210c5b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5081206-ceb5-4ad2-9e02-143ad4fd2cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    recall_score,\n",
    "    precision_score\n",
    ")\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from src.utils.features_manager import get_features_by_property\n",
    "\n",
    "# Configs Pandas\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f554cfd6-788e-4b54-addd-6160b40642e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = Path().resolve().parents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c1e93c-ac25-4b81-b9fb-03ae759d0f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(os.path.join(project_root, \"data\", \"processed\", \"train.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc90edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_config_path = os.path.join(project_root, \"src\", \"data\", \"config\", \"features.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd25b1c",
   "metadata": {},
   "source": [
    "# Load Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dffd9ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder(encoder):\n",
    "    with open(os.path.join(project_root, \"models\", \"encoders\", f\"{encoder}.pkl\"), \"rb\") as f:\n",
    "        encoder = pickle.load(f)\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ba69bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_type = load_encoder(\"feature_type\")\n",
    "fill_numeric = load_encoder(\"fill_numeric\")\n",
    "string_encoder = load_encoder(\"string_encoder\")\n",
    "selector = load_encoder(\"selector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e325e9",
   "metadata": {},
   "source": [
    "## Gerando selector_2 com features selecionadas pelo Boruta + RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b4d7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_boruta = get_features_by_property(features_config_path, \"selected_by_boruta\")\n",
    "selection_rfecv = get_features_by_property(features_config_path, \"selected_by_rfecv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad03846",
   "metadata": {},
   "source": [
    "## Aplicando encoders que não dependem da amostragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f5c6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = fill_numeric.transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043c1ed",
   "metadata": {},
   "source": [
    "# Separando conjunto de validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca301de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (103055, 38) | # 5336 fraudes | Bad rate: 5.18%\n",
      "Shape val: (11451, 38) | # 593 fraudes | Bad rate: 5.18%\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df_train, test_size=0.1, random_state=911, stratify=df_train[\"fraude\"])\n",
    "print(f\"Shape train: {df_train.shape} | # {df_train['fraude'].sum()} fraudes | Bad rate: {df_train['fraude'].mean():.2%}\")\n",
    "print(f\"Shape val: {df_val.shape} | # {df_val['fraude'].sum()} fraudes | Bad rate: {df_val['fraude'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55fbd84",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fe8867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_metrics(y_test, y_pred_proba, max_fpr=0.05):\n",
    "    \"\"\"Model performance metrics\"\"\"\n",
    "    \n",
    "    # Calculate ROC AUC score with a partial area under the curve\n",
    "    roc_auc_partial = float(roc_auc_score(y_test, y_pred_proba, max_fpr=max_fpr))\n",
    "    \n",
    "    # Calculate recall and precision with a threshold based on max_fpr\n",
    "    threshold = np.percentile(y_pred_proba, 100 * (1 - max_fpr))\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    recall_partial = recall_score(y_test, y_pred)\n",
    "    precision_partial = precision_score(y_test, y_pred)\n",
    "    \n",
    "    metrics = {        \n",
    "        f'ROC_AUC@{max_fpr}': roc_auc_partial,\n",
    "        f'Recall@{max_fpr}': recall_partial,\n",
    "        f'Precision@{max_fpr}': precision_partial\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e6ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_parquet(os.path.join(project_root, \"data\", \"raw\", \"dados.parquet\"))\n",
    "df_baseline = df_train[['index', 'fraude', 'week_of_the_year']].merge(df_raw[['index', 'score']], left_on=\"index\", right_on=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27bd8676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROC_AUC@0.05': 0.5658434505779224, 'Recall@0.05': 0.24756371814092953, 'Precision@0.05': 0.23699318263365626}\n"
     ]
    }
   ],
   "source": [
    "baseline_metrics = generate_model_metrics(df_baseline['fraude'], df_baseline['score'], max_fpr=0.05)\n",
    "print(baseline_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ac36e",
   "metadata": {},
   "source": [
    "# Criando Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a3592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo métrica de avaliação\n",
    "def partial_roc_auc(y_true, y_score, max_fpr=0.05):\n",
    "    return roc_auc_score(y_true, y_score, max_fpr=max_fpr)\n",
    "\n",
    "partial_roc_auc_scorer = make_scorer(partial_roc_auc, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8684e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(model, param_distributions, X_train, y_train, scaler=False, n_iter=40, cv=3, scoring=partial_roc_auc_scorer, random_state=911, verbose=1):\n",
    "    \n",
    "    if scaler:\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('string_encoder', string_encoder),\n",
    "            ('selector', selector),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('imputer', SimpleImputer(strategy='mean')), # FIX: scaler estava gerando NaN\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "    else:\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('string_encoder', string_encoder),\n",
    "            ('selector', selector),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        random_state=random_state,\n",
    "        n_jobs=1,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_estimator = random_search.best_estimator_\n",
    "    best_params = random_search.best_params_\n",
    "    \n",
    "    return best_estimator, best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ed3987",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2d15f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'classifier__C': np.logspace(-4, 4, 20),\n",
    "    'classifier__penalty': ['l1', 'l2'],\n",
    "    'classifier__solver': ['liblinear'],\n",
    "    'selector__features': [selection_boruta, selection_rfecv]\n",
    "}\n",
    "\n",
    "best_estimator, best_params = tune_model(\n",
    "    LogisticRegression(n_jobs=-1, class_weight='balanced'),\n",
    "    param_distributions,\n",
    "    df_train.drop(columns=['fraude']),\n",
    "    df_train['fraude'],\n",
    "    scaler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c168fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'selector__features': ['monto', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'l', 'm', 'n', 'o', 'p', 'hour', 'dawn_operation', 'monto_div_a', 'monto_div_b', 'monto_div_c', 'monto_div_d', 'monto_div_e', 'monto_div_f', 'monto_div_h', 'monto_div_k', 'monto_div_l', 'monto_div_m', 'monto_div_hour', 'monto_div_weekday', 'f_lower', 'l_lower', 'm_lower', 'n_lower'], 'classifier__solver': 'liblinear', 'classifier__penalty': 'l1', 'classifier__C': np.float64(0.615848211066026)}\n",
      "Train metrics\n",
      "{'ROC_AUC@0.05': 0.6300248049859843, 'Recall@0.05': 0.3495127436281859, 'Precision@0.05': 0.361925092179313}\n",
      "Val metrics\n",
      "{'ROC_AUC@0.05': 0.6293680828890372, 'Recall@0.05': 0.3524451939291737, 'Precision@0.05': 0.3647469458987784}\n"
     ]
    }
   ],
   "source": [
    "print('Best params: ', best_params)\n",
    "\n",
    "print('Train metrics')\n",
    "y_pred_train = best_estimator.predict_proba(df_train.drop(columns=['fraude']))[:, 1] * 100\n",
    "print(generate_model_metrics(df_train['fraude'], y_pred_train, max_fpr=0.05))\n",
    "\n",
    "print('Val metrics')\n",
    "y_pred_val = best_estimator.predict_proba(df_val.drop(columns=['fraude']))[:, 1] * 100\n",
    "print(generate_model_metrics(df_val['fraude'], y_pred_val, max_fpr=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ce754",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcaa8aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'classifier__n_estimators': [50, 100, 200, 300],\n",
    "    'classifier__max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'classifier__max_features': ['sqrt', 'log2'],\n",
    "    'classifier__min_samples_leaf': [4, 8, 16, 32],\n",
    "    'selector__features': [selection_boruta, selection_rfecv]\n",
    "}\n",
    "\n",
    "best_estimator, best_params = tune_model(\n",
    "    RandomForestClassifier(n_jobs=-1, class_weight='balanced'),\n",
    "    param_distributions,\n",
    "    df_train.drop(columns=['fraude']),\n",
    "    df_train['fraude'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f8ee423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'selector__features': ['monto', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'l', 'm', 'n', 'o', 'p', 'hour', 'dawn_operation', 'monto_div_a', 'monto_div_b', 'monto_div_c', 'monto_div_d', 'monto_div_e', 'monto_div_f', 'monto_div_h', 'monto_div_k', 'monto_div_l', 'monto_div_m', 'monto_div_hour', 'monto_div_weekday', 'f_lower', 'l_lower', 'm_lower', 'n_lower'], 'classifier__n_estimators': 300, 'classifier__min_samples_leaf': 16, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 4}\n",
      "Train metrics\n",
      "{'ROC_AUC@0.05': 0.6212135966279939, 'Recall@0.05': 0.3268365817091454, 'Precision@0.05': 0.33844362507277315}\n",
      "Val metrics\n",
      "{'ROC_AUC@0.05': 0.6093464962697307, 'Recall@0.05': 0.31197301854974707, 'Precision@0.05': 0.3228621291448517}\n"
     ]
    }
   ],
   "source": [
    "print('Best params: ', best_params)\n",
    "\n",
    "print('Train metrics')\n",
    "y_pred_train = best_estimator.predict_proba(df_train.drop(columns=['fraude']))[:, 1] * 100\n",
    "print(generate_model_metrics(df_train['fraude'], y_pred_train, max_fpr=0.05))\n",
    "\n",
    "print('Val metrics')\n",
    "y_pred_val = best_estimator.predict_proba(df_val.drop(columns=['fraude']))[:, 1] * 100\n",
    "print(generate_model_metrics(df_val['fraude'], y_pred_val, max_fpr=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae91af7",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f70becf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'classifier__num_leaves': [7, 15, 31, 51],\n",
    "    'classifier__learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2],\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "    'selector__features': [selection_boruta, selection_rfecv]\n",
    "}\n",
    "\n",
    "best_estimator, best_params = tune_model(\n",
    "    LGBMClassifier(n_jobs=-1, class_weight='balanced', verbose=-1),\n",
    "    param_distributions,\n",
    "    df_train.drop(columns=['fraude']),\n",
    "    df_train['fraude'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb776e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'selector__features': ['a', 'b', 'f', 'l', 'm', 'n', 'o', 'p', 'monto_div_c', 'monto_div_d', 'monto_div_f', 'monto_div_h', 'monto_div_l', 'monto_div_m', 'monto_div_hour', 'f_lower', 'l_lower', 'm_lower', 'n_lower'], 'classifier__subsample': 0.8, 'classifier__num_leaves': 51, 'classifier__n_estimators': 100, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.03}\n",
      "Train metrics\n",
      "{'ROC_AUC@0.05': 0.6487485559922371, 'Recall@0.05': 0.37724887556221887, 'Precision@0.05': 0.3906462254997089}\n",
      "Val metrics\n",
      "{'ROC_AUC@0.05': 0.6353317733501662, 'Recall@0.05': 0.35413153456998314, 'Precision@0.05': 0.36649214659685864}\n"
     ]
    }
   ],
   "source": [
    "print('Best params: ', best_params)\n",
    "\n",
    "print('Train metrics')\n",
    "y_pred_train = best_estimator.predict_proba(df_train.drop(columns=['fraude']))[:, 1] * 100\n",
    "print(generate_model_metrics(df_train['fraude'], y_pred_train, max_fpr=0.05))\n",
    "\n",
    "print('Val metrics')\n",
    "y_pred_val = best_estimator.predict_proba(df_val.drop(columns=['fraude']))[:, 1] * 100\n",
    "print(generate_model_metrics(df_val['fraude'], y_pred_val, max_fpr=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c29e9b",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc09e95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "num_neg = (df_train['fraude'] == 0).sum()\n",
    "num_pos = (df_train['fraude'] == 1).sum()\n",
    "scale_pos_weight = num_neg / num_pos\n",
    "\n",
    "param_distributions = {\n",
    "    'classifier__n_estimators': [100, 200, 300, 500],\n",
    "    'classifier__max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'classifier__learning_rate': [0.01, 0.025, 0.05, 0.1, 0.2],\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'classifier__scale_pos_weight': [scale_pos_weight],\n",
    "    'selector__features': [selection_boruta, selection_rfecv]\n",
    "}\n",
    "\n",
    "best_estimator, best_params = tune_model(\n",
    "    XGBClassifier(n_jobs=-1, use_label_encoder=False, eval_metric='logloss', verbosity=0),\n",
    "    param_distributions,\n",
    "    df_train.drop(columns=['fraude']),\n",
    "    df_train['fraude'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2d937e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'selector__features': ['a', 'b', 'f', 'l', 'm', 'n', 'o', 'p', 'monto_div_c', 'monto_div_d', 'monto_div_f', 'monto_div_h', 'monto_div_l', 'monto_div_m', 'monto_div_hour', 'f_lower', 'l_lower', 'm_lower', 'n_lower'], 'classifier__subsample': 0.8, 'classifier__scale_pos_weight': np.float64(18.31315592203898), 'classifier__n_estimators': 500, 'classifier__max_depth': 9, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.6}\n",
      "Train metrics\n",
      "{'ROC_AUC@0.05': 0.9999898110293992, 'Recall@0.05': 0.9653298350824587, 'Precision@0.05': 0.9996118765767514}\n",
      "Val metrics\n",
      "{'ROC_AUC@0.05': 0.6329545165740267, 'Recall@0.05': 0.3524451939291737, 'Precision@0.05': 0.3647469458987784}\n"
     ]
    }
   ],
   "source": [
    "print('Best params: ', best_params)\n",
    "\n",
    "print('Train metrics')\n",
    "y_pred_train = best_estimator.predict_proba(df_train.drop(columns=['fraude']))[:, 1] * 100\n",
    "print(generate_model_metrics(df_train['fraude'], y_pred_train, max_fpr=0.05))\n",
    "\n",
    "print('Val metrics')\n",
    "y_pred_val = best_estimator.predict_proba(df_val.drop(columns=['fraude']))[:, 1] * 100\n",
    "print(generate_model_metrics(df_val['fraude'], y_pred_val, max_fpr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80a0b2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(['a', 'b', 'f', 'l', 'm', 'n', 'o', 'p', 'monto_div_c', 'monto_div_d', 'monto_div_f', 'monto_div_h', 'monto_div_l', 'monto_div_m', 'monto_div_hour', 'f_lower', 'l_lower', 'm_lower', 'n_lower'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad73fddb",
   "metadata": {},
   "source": [
    "--- \n",
    "# Resumo\n",
    "\n",
    "O modelo que obteve maior resultado no conjunto de validação foi o `LGBMClassifier` com features `selected_by_rfecv`, ainda sim com um pouco de overfitting seguiremos com ele e corrigiremos este ponto no próximo tunning mais detalhado com `Optuna`, onde vamos otimizar duas métricas:\n",
    "- maximizar ROC_AUC@0.05\n",
    "- minimizar a diferença de ROC_AUC@0.05 no treino e validação"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
